---
id: selectors
sidebar_label: Selectors
title: Selectors
---

Selectors predict a bot response from a set of candidate responses.


## ResponseSelector


* **Short**

  Response Selector



* **Outputs**

  A dictionary with key as `direct_response_intent` and value containing `response` and `ranking`



* **Requires**

  `dense_features` and/or `sparse_features` for user messages and response



* **Output-Example**

  ```json
  {
      "response_selector": {
        "faq": {
          "response": {"confidence": 0.7356462617, "name": "Supports 3.5, 3.6 and 3.7, recommended version is 3.6"},
          "ranking": [
              {"confidence": 0.7356462617, "name": "Supports 3.5, 3.6 and 3.7, recommended version is 3.6"},
              {"confidence": 0.2134543431, "name": "You can ask me about how to get started"}
          ]
        }
      }
  }
  ```



* **Description**

  Response Selector component can be used to build a response retrieval model to directly predict a bot response from
  a set of candidate responses. The prediction of this model is used by [Retrieval Actions](../retrieval-actions).
  It embeds user inputs and response labels into the same space and follows the exact same
  neural network architecture and optimization as the [DIETClassifier](../components/intent-classifiers.mdx#dietclassifier).

  :::note
  If during prediction time a message contains **only** words unseen during training
  and no Out-Of-Vocabulary preprocessor was used, an empty response `None` is predicted with confidence
  `0.0`. This might happen if you only use the [CountVectorsFeaturizer](../components/featurizers.mdx#countvectorsfeaturizer) with a `word` analyzer
  as featurizer. If you use the `char_wb` analyzer, you should always get a response with a confidence
  value `> 0.0`.

  :::



* **Configuration**

  The algorithm includes almost all the hyperparameters that [DIETClassifier](../components/intent-classifiers.mdx#dietclassifier) uses.
  If you want to adapt your model, start by modifying the following parameters:

  * `epochs`:
    This parameter sets the number of times the algorithm will see the training data (default: `300`).
    One `epoch` is equals to one forward pass and one backward pass of all the training examples.
    Sometimes the model needs more epochs to properly learn.
    Sometimes more epochs don't influence the performance.
    The lower the number of epochs the faster the model is trained.

  * `hidden_layers_sizes`:
    This parameter allows you to define the number of feed forward layers and their output
    dimensions for user messages and intents (default: `text: [256, 128], label: [256, 128]`).
    Every entry in the list corresponds to a feed forward layer.
    For example, if you set `text: [256, 128]`, we will add two feed forward layers in front of
    the transformer. The vectors of the input tokens (coming from the user message) will be passed on to those
    layers. The first layer will have an output dimension of 256 and the second layer will have an output
    dimension of 128. If an empty list is used (default behavior), no feed forward layer will be
    added.
    Make sure to use only positive integer values. Usually, numbers of power of two are used.
    Also, it is usual practice to have decreasing values in the list: next value is smaller or equal to the
    value before.

  * `embedding_dimension`:
    This parameter defines the output dimension of the embedding layers used inside the model (default: `20`).
    We are using multiple embeddings layers inside the model architecture.
    For example, the vector of the complete utterance and the intent is passed on to an embedding layer before
    they are compared and the loss is calculated.

  * `number_of_transformer_layers`:
    This parameter sets the number of transformer layers to use (default: `0`).
    The number of transformer layers corresponds to the transformer blocks to use for the model.

  * `transformer_size`:
    This parameter sets the number of units in the transformer (default: `None`).
    The vectors coming out of the transformers will have the given `transformer_size`.

  * `weight_sparsity`:
    This parameter defines the fraction of kernel weights that are set to 0 for all feed forward layers
    in the model (default: `0.8`). The value should be between 0 and 1. If you set `weight_sparsity`
    to 0, no kernel weights will be set to 0, the layer acts as a standard feed forward layer. You should not
    set `weight_sparsity` to 1 as this would result in all kernel weights being 0, i.e. the model is not able
    to learn.

  In addition, the component can also be configured to train a response selector for a particular retrieval intent.
  The parameter `retrieval_intent` sets the name of the intent for which this response selector model is trained.
  Default is `None`, i.e. the model is trained for all retrieval intents.

  <details>
    <summary>
      The above configuration parameters are the ones you should configure to fit your model to your data.
      However, additional parameters exist that can be adapted.
    </summary>

    ```
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | Parameter                       | Default Value     | Description                                                  |
    +=================================+===================+==============================================================+
    | hidden_layers_sizes             | text: [256, 128]  | Hidden layer sizes for layers before the embedding layers    |
    |                                 | label: [256, 128] | for user messages and labels. The number of hidden layers is |
    |                                 |                   | equal to the length of the corresponding.                    |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | share_hidden_layers             | False             | Whether to share the hidden layer weights between user       |
    |                                 |                   | messages and labels.                                         |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | transformer_size                | None              | Number of units in transformer.                              |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | number_of_transformer_layers    | 0                 | Number of transformer layers.                                |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | number_of_attention_heads       | 4                 | Number of attention heads in transformer.                    |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_key_relative_attention      | False             | If 'True' use key relative embeddings in attention.          |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_value_relative_attention    | False             | If 'True' use value relative embeddings in attention.        |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | max_relative_position           | None              | Maximum position for relative embeddings.                    |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | unidirectional_encoder          | False             | Use a unidirectional or bidirectional encoder.               |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | batch_size                      | [64, 256]         | Initial and final value for batch sizes.                     |
    |                                 |                   | Batch size will be linearly increased for each epoch.        |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | batch_strategy                  | "balanced"        | Strategy used when creating batches.                         |
    |                                 |                   | Can be either 'sequence' or 'balanced'.                      |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | epochs                          | 300               | Number of epochs to train.                                   |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | random_seed                     | None              | Set random seed to any 'int' to get reproducible results.    |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | learning_rate                   | 0.001             | Initial learning rate for the optimizer.                     |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | embedding_dimension             | 20                | Dimension size of embedding vectors.                         |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | dense_dimension                 | text: 512         | Dense dimension for sparse features to use if no dense       |
    |                                 | label: 512        | features are present.                                        |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | concat_dimension                | text: 512         | Concat dimension for sequence and sentence features.         |
    |                                 | label: 512        |                                                              |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | number_of_negative_examples     | 20                | The number of incorrect labels. The algorithm will minimize  |
    |                                 |                   | their similarity to the user input during training.          |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | similarity_type                 | "auto"            | Type of similarity measure to use, either 'auto' or 'cosine' |
    |                                 |                   | or 'inner'.                                                  |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | loss_type                       | "softmax"         | The type of the loss function, either 'softmax' or 'margin'. |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | ranking_length                  | 10                | Number of top actions to normalize scores for loss type      |
    |                                 |                   | 'softmax'. Set to 0 to turn off normalization.               |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | maximum_positive_similarity     | 0.8               | Indicates how similar the algorithm should try to make       |
    |                                 |                   | embedding vectors for correct labels.                        |
    |                                 |                   | Should be 0.0 < ... < 1.0 for 'cosine' similarity type.      |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | maximum_negative_similarity     | -0.4              | Maximum negative similarity for incorrect labels.            |
    |                                 |                   | Should be -1.0 < ... < 1.0 for 'cosine' similarity type.     |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_maximum_negative_similarity | True              | If 'True' the algorithm only minimizes maximum similarity    |
    |                                 |                   | over incorrect intent labels, used only if 'loss_type' is    |
    |                                 |                   | set to 'margin'.                                             |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | scale_loss                      | True              | Scale loss inverse proportionally to confidence of correct   |
    |                                 |                   | prediction.                                                  |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | regularization_constant         | 0.002             | The scale of regularization.                                 |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | negative_margin_scale           | 0.8               | The scale of how important is to minimize the maximum        |
    |                                 |                   | similarity between embeddings of different labels.           |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | weight_sparsity                 | 0.8               | Sparsity of the weights in dense layers.                     |
    |                                 |                   | Value should be between 0 and 1.                             |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | drop_rate                       | 0.2               | Dropout rate for encoder. Value should be between 0 and 1.   |
    |                                 |                   | The higher the value the higher the regularization effect.   |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | drop_rate_attention             | 0.0               | Dropout rate for attention. Value should be between 0 and 1. |
    |                                 |                   | The higher the value the higher the regularization effect.   |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_sparse_input_dropout        | False             | If 'True' apply dropout to sparse input tensors.             |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_dense_input_dropout         | False             | If 'True' apply dropout to dense input tensors.              |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | evaluate_every_number_of_epochs | 20                | How often to calculate validation accuracy.                  |
    |                                 |                   | Set to '-1' to evaluate just once at the end of training.    |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | evaluate_on_number_of_examples  | 0                 | How many examples to use for hold out validation set.        |
    |                                 |                   | Large values may hurt performance, e.g. model accuracy.      |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | use_masked_language_model       | False             | If 'True' random tokens of the input message will be masked  |
    |                                 |                   | and the model should predict those tokens.                   |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | retrieval_intent                | None              | Name of the intent for which this response selector model is |
    |                                 |                   | trained.                                                     |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | tensorboard_log_directory       | None              | If you want to use tensorboard to visualize training         |
    |                                 |                   | metrics, set this option to a valid output directory. You    |
    |                                 |                   | can view the training metrics after training in tensorboard  |
    |                                 |                   | via 'tensorboard --logdir <path-to-given-directory>'.        |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | tensorboard_log_level           | "epoch"           | Define when training metrics for tensorboard should be       |
    |                                 |                   | logged. Either after every epoch ("epoch") or for every      |
    |                                 |                   | training step ("minibatch").                                 |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    | featurizers                     | []                | List of featurizer names (alias names). Only features        |
    |                                 |                   | coming from the listed names are used. If list is empty      |
    |                                 |                   | all available features are used.                             |
    +---------------------------------+-------------------+--------------------------------------------------------------+
    ```

    :::note
    For `cosine` similarity `maximum_positive_similarity` and `maximum_negative_similarity` should
    be between `-1` and `1`.

    :::

    :::note
    There is an option to use linearly increasing batch size. The idea comes from
    [https://arxiv.org/abs/1711.00489](https://arxiv.org/abs/1711.00489).
    In order to do it pass a list to `batch_size`, e.g. `"batch_size": [64, 256]` (default behavior).
    If constant `batch_size` is required, pass an `int`, e.g. `"batch_size": 64`.

    :::

    :::note
    Parameter `maximum_negative_similarity` is set to a negative value to mimic the original
    starspace algorithm in the case `maximum_negative_similarity = maximum_positive_similarity`
    and `use_maximum_negative_similarity = False`.
    See [starspace paper](https://arxiv.org/abs/1709.03856) for details.

    :::
  </details>
