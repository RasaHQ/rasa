---
sidebar_label: rasa.graph_components.validators.finetuning_validator
title: rasa.graph_components.validators.finetuning_validator
---
## FinetuningValidator Objects

```python
class FinetuningValidator(GraphComponent)
```

Component that checks whether fine-tuning is possible.

This is a component at the beginning of the graph which receives all training data
and raises an exception in case `is_finetuning` is `True` and finetuning is not
possible (e.g. because new labels were added).
In case we are doing a regular training (and not finetuning) this persists the
necessary information extracted from the training data to be able to validate when
initialized via load whether we can finetune.

Finetuning is possible if, compared to the initial training phase, it holds that
1. the configuration (except for &quot;epoch&quot; keys) does not change
2. the domain (except for &quot;responses&quot;) does not change - or we&#x27;re not finetuning
   the core part
3. the intents, entities, entity groups, entity roles, and action names that
   appeared in the original NLU training data, appear in the NLU training data
   used for finetuning, and no new such items (i.e. intents, entities, entity
   groups, entity roles, or action names) have been added, compared to the original
   training data - or we&#x27;re not finetuning the nlu part.
Note that even though conditions 2. and 3. differ based on which part we finetune,
condition 1. always covers both parts, i.e. NLU and Core.

#### get\_default\_config

```python
@staticmethod
def get_default_config() -> Dict[Text, Any]
```

Default config for ProjectProvider.

#### \_\_init\_\_

```python
def __init__(config: Dict[Text, Any], model_storage: ModelStorage, resource: Resource, execution_context: ExecutionContext, fingerprints: Optional[Dict[Text, Text]] = None) -> None
```

Instantiates a `FineTuningValidator`.

**Arguments**:

- `model_storage` - Storage which graph components can use to persist and load
  themselves.
- `resource` - Resource locator for this component which can be used to persist
  and load itself from the `model_storage`.
- `execution_context` - Information about the current graph run.
- `fingerprints` - a dictionary of fingerprints generated by a
  `FineTuningValidator`

#### validate

```python
def validate(importer: TrainingDataImporter) -> TrainingDataImporter
```

Validates whether we can finetune Core and NLU when finetuning is enabled.

**Arguments**:

- `importer` - a training data importer
  

**Raises**:

  `InvalidConfigException` if there is a conflict
  

**Returns**:

  Training Data Importer.

#### create

```python
@classmethod
def create(cls, config: Dict[Text, Any], model_storage: ModelStorage, resource: Resource, execution_context: ExecutionContext) -> FinetuningValidator
```

Creates a new `FineTuningValidator` (see parent class for full docstring).

#### persist

```python
def persist() -> None
```

Persists this `FineTuningValidator`.

#### load

```python
@classmethod
def load(cls, config: Dict[Text, Any], model_storage: ModelStorage, resource: Resource, execution_context: ExecutionContext, **kwargs: Any, ,) -> GraphComponent
```

Loads a `FineTuningValidator` (see parent class for full docstring).

