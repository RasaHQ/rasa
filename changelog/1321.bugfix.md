Support text completions endpoint when using self hosted models.

The `use_chat_completions_endpoint` parameter is now supported when using self-hosted models. This parameter is used to enable the use of the chat completions endpoint when using a self-hosted model. This parameter is set to `True` by default.
To use the text completions endpoint, set `use_chat_completions_endpoint` to `False` in the `llm` section of the component.

Usage:
```yaml
llm:
    provider: self-hosted
    model: meta-llama/Meta-Llama-3-8B
    api_base: "https://my-endpoint/v1"
    use_chat_completions_endpoint: false
```
