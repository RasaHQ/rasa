Configure LLM-as-Judge settings in the `llm_as_judge` section of the `conftest.yml` file.
These settings will be used to evaluate the groundedness and relevance of generated bot responses.
The `conftest.yml` is discoverable as long as it is in the root directory of the assistant project, 
at the same level as the `config.yml` file.

If the `conftest.yml` file is not present in the root directory, the default LLM judge settings will be used.
