Configure [LLM-as-Judge settings](https://rasa.com/docs/rasa-pro/testing/e2e-testing-assertions/assertions-installation#generative-response-llm-judge-configuration)
in the `llm_as_judge` section of the `conftest.yml` file.
These settings will be used to evaluate the groundedness and relevance of generated bot responses.
The `conftest.yml` is discoverable as long as it is in the root directory of the assistant project, 
at the same level as the `config.yml` file.

If the `conftest.yml` file is not present in the root directory, the default LLM judge settings will be used.
